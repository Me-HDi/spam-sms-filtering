{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam SMS Filtering\n",
    "------------------------------\n",
    "### *using LSTM and Convolution layers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Necessary importings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "ham\n",
      "Ok lar... Joking wif u oni...\n",
      "\n",
      "spam\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading data from a text file\n",
    "file = open('SMSSpamCollection.txt', 'r')\n",
    "datalines = file.readlines()\n",
    "\n",
    "# create text list for raw sms text, and label list for their labels (spam or ham) \n",
    "text = []\n",
    "label = []\n",
    "for line in datalines:\n",
    "    line = line.split('\\t')\n",
    "    label.append(line[0])\n",
    "    text.append(line[1].split('\\n')[0])\n",
    "\n",
    "# printing some sms texts and their labels     \n",
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print(text[i]+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5574 entries, 0 to 5573\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5574 non-null   object\n",
      " 1   text    5574 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "\n",
      "Labels counts:\n",
      "ham     4827\n",
      "spam     747\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of text and label lists to have a better sense of the data\n",
    "df = pd.DataFrame({'label':label, 'text':text})\n",
    "\n",
    "print(df.info())\n",
    "print('\\nLabels counts:')\n",
    "print(df.label.value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 13.4% of the data is spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data intro train and test, with 30% for testing. Because of the small proportion of spam labels, We make sure that the two partitions have the same proportion of spam labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# convert labels to numeric type : 1 for spam and 0 for ham\n",
    "y = df.label.apply(lambda x: 1 if x=='spam' else 0).values\n",
    "\n",
    "# plitting data\n",
    "text_train, text_test, y_train, y_test = train_test_split(text, y, test_size=0.3,stratify=y,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%spam in train data: 0.1340681876441938\n",
      "%spam in test data: 0.13389121338912133\n"
     ]
    }
   ],
   "source": [
    "print('%spam in train data:', y_train.sum()/len(y_train))\n",
    "print('%spam in test data:', y_test.sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A model with an accuracy equal or below 87% on the test data is not relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text must be tokenized and converted to sequence of numbers in order to be fed into a machine learning model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Create and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_train) # the tokenizer creates a dictionary of tokens and their indexes based on text_train\n",
    "\n",
    "# Transform each sms text in text_train into a sequence of numbers\n",
    "X_train = tokenizer.texts_to_sequences(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The maximum length of a sequence\n",
    "maxlen = np.max([len(seq) for seq in X_train]) \n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to have the same sequence length in X_train, we pad these sequences with zeros to reach maxlen \n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "# we get the vocabulary size used to preprocess train_text\n",
    "# 1 is added to account for unseen words that will have index 0\n",
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and pad test data\n",
    "X_test = tokenizer.texts_to_sequences(text_test)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 189, 128)          951680    \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 189, 64)           24640     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 94, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,011,457\n",
      "Trainable params: 1,011,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Conv1D, MaxPooling1D\n",
    "\n",
    "# Instantiating the model class\n",
    "model = Sequential()\n",
    "\n",
    "# we use \"Embedding\" as first layer to have a dense representation of words.\n",
    "# each word will be represented as a vector of 128 length.   \n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=128,\n",
    "                    trainable=True,\n",
    "                    input_length=maxlen))\n",
    "\n",
    "# This convolution layer do feature selection on the embedding vector\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# adding an LSTM layer will allow the model to operate over sequences of word vectors.\n",
    "# this can be understood as interpreting words in their context\n",
    "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1)) \n",
    "# the dropouts remove 10% of input and memory cells respectively to avoid overfitting\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# summary of the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and evaluating predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efficiency, we create *fit_evaluate* function to perform model's fitting on training data and model's evaluation on testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def fit_evaluate(model, X_train, X_test, y_train, y_test, epochs=1):\n",
    "    # fitting\n",
    "    model.fit(X_train,y_train,epochs=epochs)\n",
    "    \n",
    "    # generating predictions i.e. a probability of being spam\n",
    "    predictions_proba = model.predict(X_test)\n",
    "    \n",
    "    # generating class predictions 0 (not spam) or 1 (spam)\n",
    "    predictions_class = []\n",
    "    for pred in predictions_proba:\n",
    "        if pred>=0.5:\n",
    "            predictions_class.append(1)\n",
    "        else:\n",
    "            predictions_class.append(0)\n",
    "            \n",
    "    # printing metrics about the classification\n",
    "    print('\\n-------------------------------------------------------')\n",
    "    print('\\n=============== Confusion Matrix ======================')\n",
    "    print(confusion_matrix(y_test, predictions_class))\n",
    "    print('\\n============ Classification report ====================')\n",
    "    print(classification_report(y_test, predictions_class))\n",
    "    print('---------------------------------------------------------')\n",
    "    \n",
    "    return predictions_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3901/3901 [==============================] - 18s 5ms/step - loss: 0.1771 - accuracy: 0.9457\n",
      "Epoch 2/2\n",
      "3901/3901 [==============================] - 16s 4ms/step - loss: 0.0252 - accuracy: 0.9926\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "=============== Confusion Matrix ======================\n",
      "[[1446    3]\n",
      " [  12  212]]\n",
      "\n",
      "============ Classification report ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1449\n",
      "           1       0.99      0.95      0.97       224\n",
      "\n",
      "    accuracy                           0.99      1673\n",
      "   macro avg       0.99      0.97      0.98      1673\n",
      "weighted avg       0.99      0.99      0.99      1673\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred = fit_evaluate(model, X_train, X_test, y_train, y_test, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The model performed very well: 95% as recall for the class 'spam'. Which means that the model predicts 95% of the actual spam SMSs. It also predicted 3 SMSs to be spam but they're actualy not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Investigating wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Check Out Choose Your Babe Videos @ sms.shsex....</td>\n",
       "      <td>check out choose your babe sms</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sorry I missed your call let's talk when you h...</td>\n",
       "      <td>sorry i missed your call let's talk when you h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They have a thread on the wishlist section of ...</td>\n",
       "      <td>they have a thread on the of the forums where ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TBS/PERSOLVO. been chasing us since Sept forÂ£...</td>\n",
       "      <td>been chasing us since sept definitely not payi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello darling how are you today? I would love ...</td>\n",
       "      <td>hello darling how are you today i would love t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Check Out Choose Your Babe Videos @ sms.shsex....   \n",
       "1  Sorry I missed your call let's talk when you h...   \n",
       "2  They have a thread on the wishlist section of ...   \n",
       "3  TBS/PERSOLVO. been chasing us since Sept forÂ£...   \n",
       "4  Hello darling how are you today? I would love ...   \n",
       "\n",
       "                                      processed_text  actual_label  pred_label  \n",
       "0                     check out choose your babe sms             1           0  \n",
       "1  sorry i missed your call let's talk when you h...             1           0  \n",
       "2  they have a thread on the of the forums where ...             0           1  \n",
       "3  been chasing us since sept definitely not payi...             1           0  \n",
       "4  hello darling how are you today i would love t...             1           0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexes of wrong predictions\n",
    "er = np.where(y_test + y_pred == 1)\n",
    "\n",
    "# we take raw text from text_test corresponding to these wrong predictions \n",
    "original_text = np.array(text_test)[er]\n",
    "\n",
    "# we take the tokenizer-processed version of the raw text\n",
    "tokenizer_processed_text = tokenizer.sequences_to_texts(X_test[er])\n",
    "\n",
    "# we create a data frame that recaps information about wrong predictions\n",
    "review = pd.DataFrame({'original_text':original_text,\n",
    "                       'processed_text':tokenizer_processed_text,\n",
    "                       'actual_label':y_test[er],\n",
    "                       'pred_label':np.array(y_pred)[er]}) \n",
    "\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below we can see in detail which sms texts our model had wrong, along with their the actual and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== 1 ===============================\n",
      "original_text\n",
      "Check Out Choose Your Babe Videos @ sms.shsex.netUN fgkslpoPW fgkslpo\n",
      "\n",
      "\n",
      "processed_text\n",
      "check out choose your babe sms\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 2 ===============================\n",
      "original_text\n",
      "Sorry I missed your call let's talk when you have the time. I'm on 07090201529\n",
      "\n",
      "\n",
      "processed_text\n",
      "sorry i missed your call let's talk when you have the time i'm on\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 3 ===============================\n",
      "original_text\n",
      "They have a thread on the wishlist section of the forums where ppl post nitro requests. Start from the last page and collect from the bottom up.\n",
      "\n",
      "\n",
      "processed_text\n",
      "they have a thread on the of the forums where ppl post requests start from the last page and collect from the bottom up\n",
      "\n",
      "\n",
      "actual_label\n",
      "0\n",
      "\n",
      "\n",
      "pred_label\n",
      "1\n",
      "\n",
      "\n",
      "=============================== 4 ===============================\n",
      "original_text\n",
      "TBS/PERSOLVO. been chasing us since Sept forÂ£38 definitely not paying now thanks to your information. We will ignore them. Kath. Manchester.\n",
      "\n",
      "\n",
      "processed_text\n",
      "been chasing us since sept definitely not paying now thanks to your information we will ignore them\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 5 ===============================\n",
      "original_text\n",
      "Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?\n",
      "\n",
      "\n",
      "processed_text\n",
      "hello darling how are you today i would love to have a chat why dont you tell me what you look like and what you are in to sexy\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 6 ===============================\n",
      "original_text\n",
      "88800 and 89034 are premium phone services call 08718711108\n",
      "\n",
      "\n",
      "processed_text\n",
      "and are premium phone services call\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 7 ===============================\n",
      "original_text\n",
      "Dear Voucher Holder 2 claim your 1st class airport lounge passes when using Your holiday voucher call 08704439680. When booking quote 1st class x 2\n",
      "\n",
      "\n",
      "processed_text\n",
      "dear voucher holder 2 claim your 1st class airport lounge when using your holiday voucher call when booking quote 1st class x 2\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 8 ===============================\n",
      "original_text\n",
      "ROMCAPspam Everyone around should be responding well to your presence since you are so warm and outgoing. You are bringing in a real breath of sunshine.\n",
      "\n",
      "\n",
      "processed_text\n",
      "everyone around should be responding well to your since you are so warm and you are bringing in a real breath of sunshine\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 9 ===============================\n",
      "original_text\n",
      "dating:i have had two of these. Only started after i sent a text to talk sport radio last week. Any connection do you think or coincidence?\n",
      "\n",
      "\n",
      "processed_text\n",
      "dating i have had two of these only started after i sent a text to talk sport radio last week any connection do you think or\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 10 ===============================\n",
      "original_text\n",
      "SMS. ac sun0819 posts HELLO:\"You seem cool, wanted to say hi. HI!!!\" Stop? Send STOP to 62468\n",
      "\n",
      "\n",
      "processed_text\n",
      "sms ac posts hello you seem cool wanted to say hi hi stop send stop to 62468\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 11 ===============================\n",
      "original_text\n",
      "thesmszone.com lets you send free anonymous and masked messages..im sending this message from there..do you see the potential for abuse???\n",
      "\n",
      "\n",
      "processed_text\n",
      "com lets you send free and messages im sending this message from there do you see the for\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 12 ===============================\n",
      "original_text\n",
      "LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\n",
      "\n",
      "\n",
      "processed_text\n",
      "thanks for your purchase of a video from you've been charged think you can do better why not send a video in a\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 13 ===============================\n",
      "original_text\n",
      "Cheers for the message Zogtorius. IÂ’ve been staring at my phone for an age deciding whether to text or not.\n",
      "\n",
      "\n",
      "processed_text\n",
      "cheers for the message been staring at my phone for an age deciding whether to text or not\n",
      "\n",
      "\n",
      "actual_label\n",
      "0\n",
      "\n",
      "\n",
      "pred_label\n",
      "1\n",
      "\n",
      "\n",
      "=============================== 14 ===============================\n",
      "original_text\n",
      "Can U get 2 phone NOW? I wanna chat 2 set up meet Call me NOW on 09096102316 U can cum here 2moro Luv JANE xx CallsÂ£1/minmoremobsEMSPOBox45PO139WA\n",
      "\n",
      "\n",
      "processed_text\n",
      "can u get 2 phone now i wanna chat 2 set up meet call me now on u can cum here 2moro luv jane xx callsâ£1 minmoremobsemspobox45po139wa\n",
      "\n",
      "\n",
      "actual_label\n",
      "1\n",
      "\n",
      "\n",
      "pred_label\n",
      "0\n",
      "\n",
      "\n",
      "=============================== 15 ===============================\n",
      "original_text\n",
      "Ujhhhhhhh computer shipped out with address to sandiago and parantella lane. Wtf. Poop.\n",
      "\n",
      "\n",
      "processed_text\n",
      "computer out with address to and lane wtf poop\n",
      "\n",
      "\n",
      "actual_label\n",
      "0\n",
      "\n",
      "\n",
      "pred_label\n",
      "1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(review.shape[0]):\n",
    "    print('===============================',i+1,'===============================')\n",
    "    for col in review.columns:\n",
    "        print(col)\n",
    "        print(review.iloc[i][col])\n",
    "        print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
